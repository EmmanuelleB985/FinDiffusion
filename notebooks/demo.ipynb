{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinDiffusion Demo\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load and preprocess financial data\n",
    "2. Train a conditional diffusion model\n",
    "3. Generate synthetic financial time series\n",
    "4. Evaluate the quality of generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src.models import FinancialDiffusion\n",
    "from src.data import FinancialDataModule\n",
    "from src.evaluation import validate_stylized_facts, compute_all_metrics\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data module\n",
    "data_module = FinancialDataModule(\n",
    "    tickers=[\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\"],\n",
    "    start_date=\"2015-01-01\",\n",
    "    end_date=\"2024-01-01\",\n",
    "    seq_len=252,  # 1 trading year\n",
    "    stride=21,    # ~1 month\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "data_module.setup()\n",
    "\n",
    "print(f\"Training samples: {len(data_module.train_dataset)}\")\n",
    "print(f\"Validation samples: {len(data_module.val_dataset)}\")\n",
    "print(f\"Test samples: {len(data_module.test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample data\n",
    "sample_batch = data_module.get_sample_batch()\n",
    "sample_batch_denorm = data_module.denormalize(sample_batch.numpy())\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    returns = sample_batch_denorm[i]\n",
    "    cum_ret = np.cumprod(1 + returns)\n",
    "    ax.plot(cum_ret)\n",
    "    ax.set_title(f'Sample {i+1}: Total Return = {(cum_ret[-1]-1)*100:.1f}%')\n",
    "    ax.set_xlabel('Days')\n",
    "    ax.set_ylabel('Cumulative Return')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = FinancialDiffusion(\n",
    "    seq_len=252,\n",
    "    input_dim=1,\n",
    "    d_model=128,      # Smaller for demo\n",
    "    n_layers=4,\n",
    "    n_heads=4,\n",
    "    d_ff=256,\n",
    "    d_cond=64,\n",
    "    timesteps=500,    # Fewer timesteps for demo\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Training (Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training import Trainer, TrainingConfig\n",
    "\n",
    "config = TrainingConfig(\n",
    "    epochs=5,           # Just a few epochs for demo\n",
    "    lr=1e-4,\n",
    "    use_amp=True,\n",
    "    log_every=50,\n",
    "    save_every=5,\n",
    "    use_wandb=False,\n",
    "    checkpoint_dir='../checkpoints_demo',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=data_module.train_dataloader(),\n",
    "    val_loader=data_module.val_dataloader(),\n",
    "    config=config,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (this will take a few minutes)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Generate unconditional samples\n",
    "with torch.no_grad():\n",
    "    synthetic = model.generate(\n",
    "        n_samples=100,\n",
    "        use_ddim=True,      # Faster sampling\n",
    "        ddim_steps=50,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "synthetic = synthetic.cpu().numpy()\n",
    "synthetic = data_module.denormalize(synthetic)\n",
    "\n",
    "print(f\"Generated {len(synthetic)} samples\")\n",
    "print(f\"Mean daily return: {synthetic.mean():.6f}\")\n",
    "print(f\"Std daily return: {synthetic.std():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate conditional samples (high volatility)\n",
    "with torch.no_grad():\n",
    "    high_vol = model.generate(\n",
    "        n_samples=50,\n",
    "        conditions={\"trend\": 0.0, \"volatility\": 0.40, \"regime\": \"bear\"},\n",
    "        use_ddim=True,\n",
    "        ddim_steps=50,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "high_vol = data_module.denormalize(high_vol.cpu().numpy())\n",
    "print(f\"High vol samples - Realized vol: {high_vol.std() * np.sqrt(252):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize generated samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    returns = synthetic[i]\n",
    "    cum_ret = np.cumprod(1 + returns)\n",
    "    ax.plot(cum_ret, color='blue', alpha=0.8)\n",
    "    ax.set_title(f'Synthetic {i+1}: Return={100*(cum_ret[-1]-1):.1f}%, Vol={returns.std()*np.sqrt(252):.0%}')\n",
    "    ax.set_xlabel('Days')\n",
    "\n",
    "plt.suptitle('Generated Synthetic Price Paths', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Stylized Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get real test samples\n",
    "real_samples = []\n",
    "for i in range(min(100, len(data_module.test_dataset))):\n",
    "    real_samples.append(data_module.test_dataset[i].numpy())\n",
    "real_samples = np.array(real_samples)\n",
    "real_samples = data_module.denormalize(real_samples)\n",
    "\n",
    "# Validate stylized facts\n",
    "print(\"=\" * 50)\n",
    "print(\"REAL DATA STYLIZED FACTS\")\n",
    "print(\"=\" * 50)\n",
    "real_results = validate_stylized_facts(real_samples)\n",
    "for test, result in real_results.items():\n",
    "    if test != 'summary':\n",
    "        print(f\"{test}: {'PASS' if result['passed'] else 'FAIL'} - {result['interpretation']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SYNTHETIC DATA STYLIZED FACTS\")\n",
    "print(\"=\" * 50)\n",
    "syn_results = validate_stylized_facts(synthetic)\n",
    "for test, result in syn_results.items():\n",
    "    if test != 'summary':\n",
    "        print(f\"{test}: {'PASS' if result['passed'] else 'FAIL'} - {result['interpretation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(real_samples.flatten(), bins=100, alpha=0.7, label='Real', density=True)\n",
    "axes[0].hist(synthetic.flatten(), bins=100, alpha=0.7, label='Synthetic', density=True)\n",
    "axes[0].set_xlabel('Daily Returns')\n",
    "axes[0].set_ylabel('Density')\n",
    "axes[0].set_title('Return Distribution')\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim(-0.1, 0.1)\n",
    "\n",
    "# ACF of squared returns\n",
    "max_lag = 20\n",
    "real_sq = real_samples.flatten() ** 2\n",
    "syn_sq = synthetic.flatten() ** 2\n",
    "\n",
    "acf_real = [np.corrcoef(real_sq[:-lag], real_sq[lag:])[0,1] for lag in range(1, max_lag+1)]\n",
    "acf_syn = [np.corrcoef(syn_sq[:-lag], syn_sq[lag:])[0,1] for lag in range(1, max_lag+1)]\n",
    "\n",
    "x = np.arange(1, max_lag+1)\n",
    "axes[1].bar(x - 0.2, acf_real, width=0.4, label='Real', alpha=0.7)\n",
    "axes[1].bar(x + 0.2, acf_syn, width=0.4, label='Synthetic', alpha=0.7)\n",
    "axes[1].set_xlabel('Lag')\n",
    "axes[1].set_ylabel('ACF')\n",
    "axes[1].set_title('Autocorrelation of Squared Returns\\n(Volatility Clustering)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comprehensive Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_all_metrics(real_samples, synthetic)\n",
    "\n",
    "print(\"\\nDISTRIBUTION METRICS\")\n",
    "print(\"-\" * 30)\n",
    "for k, v in metrics['distribution'].items():\n",
    "    print(f\"  {k}: {v:.6f}\")\n",
    "\n",
    "print(\"\\nTEMPORAL METRICS\")\n",
    "print(\"-\" * 30)\n",
    "for k, v in metrics['temporal'].items():\n",
    "    print(f\"  {k}: {v:.6f}\")\n",
    "\n",
    "print(\"\\nDIVERSITY METRICS\")\n",
    "print(\"-\" * 30)\n",
    "for k, v in metrics['diversity'].items():\n",
    "    print(f\"  {k}: {v:.6f}\")\n",
    "\n",
    "print(\"\\nOVERALL SCORE\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"  Overall: {metrics['summary']['overall_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save synthetic data for later use\n",
    "df = pd.DataFrame(synthetic)\n",
    "df.columns = [f't_{i}' for i in range(synthetic.shape[1])]\n",
    "df.to_csv('../outputs/synthetic_returns_demo.csv', index=False)\n",
    "print(\"Saved synthetic returns to outputs/synthetic_returns_demo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demo showed:\n",
    "- How to load and preprocess financial data using Yahoo Finance\n",
    "- Training a conditional diffusion model on return sequences\n",
    "- Generating synthetic data with controllable conditions (trend, volatility, regime)\n",
    "- Evaluating data quality using stylized facts tests\n",
    "\n",
    "For production use:\n",
    "- Train for more epochs (50-100)\n",
    "- Use larger model dimensions\n",
    "- Include more tickers for diversity\n",
    "- Enable Weights & Biases for experiment tracking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
